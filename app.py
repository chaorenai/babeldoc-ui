import gradio as gr
import subprocess
import os
import uuid
import requests
import json
from datetime import datetime

OUTPUT_DIR = "output"
UPLOAD_DIR = "uploads"
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

MODEL_PRESETS = {
    "OpenAI": {
        "base_url": os.getenv("DEFAULT_OPENAI_BASE_URL", "https://api.openai.com/v1"),
        "api_key": os.getenv("DEFAULT_OPENAI_API_KEY", ""),
        "default_model": os.getenv("DEFAULT_OPENAI_DEFAULT_MODEL", "gpt-4o")
    },
    "DeepSeek": {
        "base_url": os.getenv("DEFAULT_DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1"),
        "api_key": os.getenv("DEFAULT_DEEPSEEK_API_KEY", ""),
        "default_model": os.getenv("DEFAULT_DEEPSEEK_DEFAULT_MODEL", "deepseek-chat")
    },
    "Ollama (æœ¬åœ°æ¨¡å‹)": {
        "base_url": os.getenv("DEFAULT_OLLAMA_BASE_URL", "http://localhost:11434/v1"),
        "api_key": os.getenv("DEFAULT_OLLAMA_API_KEY", ""),
        "default_model": os.getenv("DEFAULT_OLLAMA_DEFAULT_MODEL", "llama3")
    }
}
def run_babeldoc_translation(input_path, output_path, model_name, base_url, api_key, lang_in, lang_out,
                             dual_output, no_watermark, skip_clean, rich_text_disable,
                             enhance, max_pages, min_length):
    command = [
        "babeldoc",
        "--files", input_path,
        "--openai",
        "--openai-model", model_name,
        "--openai-base-url", base_url,
        "--openai-api-key", api_key,
        "--lang-in", lang_in,
        "--lang-out", lang_out,
        "--output", output_path
    ]

    if not dual_output:
        command.append("--no-dual")
    if no_watermark:
        command.extend(["--watermark-output-mode", "no_watermark"])
    if skip_clean:
        command.append("--skip-clean")
    if rich_text_disable:
        command.append("--disable-rich-text-translate")
    if enhance:
        command.append("--enhance-compatibility")
    if max_pages:
        command.extend(["--max-pages-per-part", str(max_pages)])
    if min_length:
        command.extend(["--min-text-length", str(min_length)])

    print("ğŸ“¦ æ‰§è¡Œå‘½ä»¤ï¼š", " ".join(command))

    try:
        subprocess.run(command, check=True)
    except subprocess.CalledProcessError as e:
        return f"ç¿»è¯‘å‡ºé”™ï¼š{str(e)}", None

    pdf_files = sorted(
        [f for f in os.listdir(output_path) if f.endswith(".pdf")],
        key=lambda x: os.path.getmtime(os.path.join(output_path, x)),
        reverse=True
    )
    if not pdf_files:
        return "ç¿»è¯‘å¤±è´¥ï¼šæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶", None

    translated_path = os.path.join(output_path, pdf_files[0])
    return "ç¿»è¯‘å®Œæˆ âœ…ï¼Œç‚¹å‡»ä¸‹æ–¹é“¾æ¥ä¸‹è½½ï¼š", translated_path

def get_ollama_models():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            tags = response.json().get("models", [])
            return [tag["name"] for tag in tags]
    except Exception:
        pass
    return ["llama3"]

def get_openai_models(api_key, base_url):
    try:
        headers = {"Authorization": f"Bearer {api_key}"}
        response = requests.get(f"{base_url}/models", headers=headers, timeout=5)
        if response.status_code == 200:
            models = response.json().get("data", [])
            return [m["id"] for m in models]
    except Exception:
        pass
    return []

def translate_pdf(pdf_file, provider, api_key, base_url, model_name,
                  lang_in, lang_out, dual_output, no_watermark,
                  skip_clean, rich_text_disable, enhance, max_pages, min_length):
    if not pdf_file:
        return "è¯·ä¸Šä¼  PDF æ–‡ä»¶", None

    upload_pdfs = sorted(
        [f for f in os.listdir(UPLOAD_DIR) if f.endswith(".pdf")],
        key=lambda x: os.path.getmtime(os.path.join(UPLOAD_DIR, x)),
        reverse=True
    )
    for old_file in upload_pdfs[30:]:
        try:
            os.remove(os.path.join(UPLOAD_DIR, old_file))
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§ä¸Šä¼ æ–‡ä»¶ï¼š{old_file}ï¼ŒåŸå› ï¼š{e}")

    file_id = str(uuid.uuid4())
    filename = os.path.basename(pdf_file)
    name_root = os.path.splitext(filename)[0]
    input_path = os.path.join(UPLOAD_DIR, f"{file_id}_{filename}")
    with open(pdf_file, "rb") as src, open(input_path, "wb") as dst:
        dst.write(src.read())

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_subdir = os.path.join(OUTPUT_DIR, f"{name_root}_{timestamp}")
    os.makedirs(output_subdir, exist_ok=True)

    print("âš™ï¸ å®é™…è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼š", input_path)
    return run_babeldoc_translation(
        input_path, output_subdir, model_name, base_url, api_key,
        lang_in, lang_out, dual_output, no_watermark,
        skip_clean, rich_text_disable, enhance, max_pages, min_length
    )

def update_provider(provider):
    preset = MODEL_PRESETS[provider]
    default_model = preset["default_model"]
    if provider == "Ollama (æœ¬åœ°æ¨¡å‹)":
        models = get_ollama_models()
        default = models[0] if models else "llama3"
        return preset["api_key"], preset["base_url"], gr.update(choices=models, value=default)
    else:
        return preset["api_key"], preset["base_url"], gr.update(choices=[default_model], value=default_model)

def refresh_models(api_key, base_url):
    models = get_openai_models(api_key, base_url)
    if not models:
        return gr.update(choices=[], value="è·å–å¤±è´¥ âŒ")
    return gr.update(choices=models, value=models[0])

with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“„ BabelDOC - å¤šæ¨¡å‹ PDF ç¿»è¯‘å·¥å…·")

    gr.Markdown(
        '''
## ğŸ“˜ å°æœæé†’æ‚¨ï¼ˆREADMEï¼‰

1. ä¸Šä¼ ä½ æƒ³ç¿»è¯‘çš„ PDF æ–‡ä»¶ï¼ˆç›®å‰ä»…æ”¯æŒ `.pdf`ï¼‰ã€‚
2. é€‰æ‹©ä½ è¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆæ”¯æŒ OpenAI / DeepSeek / æœ¬åœ° Ollamaï¼‰ã€‚
3. è¾“å…¥å¯¹åº” API Keyï¼ˆå¦‚ä½¿ç”¨ OpenAIï¼‰ã€‚
4. é€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ï¼ˆå¦‚è‹±æ–‡ â†’ ä¸­æ–‡ï¼‰ã€‚
5. æ ¹æ®éœ€è¦å‹¾é€‰é€‰é¡¹ï¼š
   - âœ… è¾“å‡ºåŒè¯­ï¼šåŸæ–‡+è¯‘æ–‡å¹¶æ’æ˜¾ç¤ºã€‚
   - âœ… æ— æ°´å°ï¼šå»é™¤â€œç”± BabelDOC ç”Ÿæˆâ€æ ‡è¯†ã€‚
   - âœ… è·³è¿‡æ¸…æ´—ï¼šä¿ç•™åŸå§‹æ’ç‰ˆï¼Œä¸å¯¹ PDF æ ¼å¼åšæ¸…ç†ã€‚
   - âœ… ç¦ç”¨å¯Œæ–‡æœ¬ï¼šé¿å…ä¿ç•™åŠ ç²—ã€è¶…é“¾æ¥ç­‰æ ¼å¼ã€‚
6. ç‚¹å‡» ğŸš€ å¼€å§‹ç¿»è¯‘ï¼Œç¨ç­‰ç‰‡åˆ»åå³å¯ä¸‹è½½ç¿»è¯‘ç»“æœã€‚
7. ç¿»è¯‘æ–‡ä»¶å°†è‡ªåŠ¨ä¿å­˜åœ¨ `output/åŸæ–‡ä»¶å_æ—¶é—´æˆ³/` ç›®å½•ä¸‹ã€‚

ğŸ“¢ æ¬¢è¿å…³æ³¨å°æœçš„Xï¼š
https://x.com/xiaodus

ğŸ“‚ æœ¬åœ°æ¨¡å‹ç”¨æˆ·è¯·ç¡®ä¿ `Ollama` æœåŠ¡å™¨å·²è¿è¡Œï¼Œå¹¶åŠ è½½æ¨¡å‹ï¼ˆå¦‚ llama3ã€gemma ç­‰ï¼‰ã€‚
'''
    )

    with gr.Row():
        pdf_file = gr.File(label="ä¸Šä¼  PDF æ–‡ä»¶", file_types=[".pdf"], type="filepath")

    with gr.Row():
        provider = gr.Radio(
            label="é€‰æ‹©ç¿»è¯‘æ¨¡å‹æ¥æº",
            choices=list(MODEL_PRESETS.keys()),
            value="OpenAI"
        )

    with gr.Row():
        api_key = gr.Text(label="API Keyï¼ˆOpenAI/DeepSeek å¡«å†™ï¼‰", type="password", value=MODEL_PRESETS["OpenAI"]["api_key"])
        base_url = gr.Text(label="API Base URL", value=MODEL_PRESETS["OpenAI"]["base_url"])
        model_name = gr.Dropdown(label="æ¨¡å‹åç§°", choices=[], value=MODEL_PRESETS["OpenAI"]['default_model'], interactive=True)
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨")

    with gr.Row():
        lang_in = gr.Dropdown(label="æºè¯­è¨€", choices=["en", "zh", "ja"], value="en")
        lang_out = gr.Dropdown(label="ç›®æ ‡è¯­è¨€", choices=["zh", "en", "ja"], value="zh")

    with gr.Row():
        dual_output = gr.Checkbox(label="è¾“å‡ºåŒè¯­ PDF", value=True)
        no_watermark = gr.Checkbox(label="æ— æ°´å°è¾“å‡º", value=True)
        skip_clean = gr.Checkbox(label="è·³è¿‡ PDF æ¸…æ´— (skip-clean)", value=True)
        rich_text_disable = gr.Checkbox(label="ç¦ç”¨å¯Œæ–‡æœ¬ç¿»è¯‘ (disable-rich-text-translate)", value=True)
        enhance = gr.Checkbox(label="å¢å¼ºå…¼å®¹æ€§ (enhance-compatibility)", value=True)
        max_pages = gr.Textbox(label="æœ€å¤§åˆ†å—é¡µæ•° (max-pages-per-part)", value="1")
        min_length = gr.Textbox(label="æœ€å°ç¿»è¯‘é•¿åº¦ (min-text-length)", value="5")

    run_button = gr.Button("ğŸš€ å¼€å§‹ç¿»è¯‘")
    status = gr.Textbox(label="çŠ¶æ€", interactive=False)
    result_pdf = gr.File(label="ç¿»è¯‘ç»“æœä¸‹è½½")

    provider.change(fn=update_provider, inputs=provider,
                    outputs=[api_key, base_url, model_name])

    refresh_btn.click(fn=refresh_models,
                      inputs=[api_key, base_url],
                      outputs=model_name)

    run_button.click(
        fn=translate_pdf,
        inputs=[pdf_file, provider, api_key, base_url, model_name,
                lang_in, lang_out, dual_output, no_watermark,
                skip_clean, rich_text_disable, enhance, max_pages, min_length],
        outputs=[status, result_pdf]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=int(os.getenv("SERVER_PORT", "7860")))
